#!/usr/bin/env python3
"""
HYBRID CONTEXT BUILDER - Constructor de contexto hÃ­brido
Combina datos existentes de Pure con nueva informaciÃ³n extraÃ­da y datos de investigadores/publicaciones
"""

import json
import logging
import os
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class HybridContextConfig:
    """ConfiguraciÃ³n para el constructor de contexto hÃ­brido"""
    existing_data_path: str = "scraped_data/scrapfly_complete_20250814_210110.json"
    new_units_data_path: str = "scraped_data/pure_knowledge_base_20250814_213019.json"
    output_path: str = "scraped_data/pure_hybrid_context.json"
    enable_researcher_extraction: bool = True
    max_context_size: int = 100000

class HybridContextBuilder:
    """Constructor de contexto hÃ­brido para Pure Universidad de la Sabana"""
    
    def __init__(self, config: HybridContextConfig):
        self.config = config
        self.existing_data = {}
        self.new_units_data = {}
        self.hybrid_context = {}
        
    def load_existing_data(self) -> bool:
        """Cargar datos existentes exitosos"""
        try:
            if not os.path.exists(self.config.existing_data_path):
                logger.warning(f"Datos existentes no encontrados: {self.config.existing_data_path}")
                return False
            
            with open(self.config.existing_data_path, 'r', encoding='utf-8') as f:
                self.existing_data = json.load(f)
            
            logger.info(f"âœ… Datos existentes cargados desde: {self.config.existing_data_path}")
            return True
            
        except Exception as e:
            logger.error(f"Error cargando datos existentes: {e}")
            return False

    def load_new_units_data(self) -> bool:
        """Cargar nueva informaciÃ³n de unidades"""
        try:
            if not os.path.exists(self.config.new_units_data_path):
                logger.warning(f"Nuevos datos de unidades no encontrados: {self.config.new_units_data_path}")
                return False
            
            with open(self.config.new_units_data_path, 'r', encoding='utf-8') as f:
                self.new_units_data = json.load(f)
            
            logger.info(f"âœ… Nuevos datos de unidades cargados: {len(self.new_units_data.get('research_units', []))} unidades")
            return True
            
        except Exception as e:
            logger.error(f"Error cargando nuevos datos de unidades: {e}")
            return False

    def extract_researchers_from_existing_data(self) -> List[Dict[str, Any]]:
        """Extraer informaciÃ³n de investigadores de datos existentes"""
        researchers = []
        
        try:
            # Buscar en datos exitosos anteriores
            sections_data = self.existing_data.get('sections_data', {})
            
            for section_name, section_data in sections_data.items():
                section_content = section_data.get('content', '')
                
                # Buscar patrones de investigadores en el contenido
                researchers_found = self.extract_researcher_patterns(section_content, section_name)
                researchers.extend(researchers_found)
            
            # Remover duplicados
            unique_researchers = []
            seen_names = set()
            
            for researcher in researchers:
                name = researcher.get('name', '').strip().lower()
                if name and name not in seen_names:
                    seen_names.add(name)
                    unique_researchers.append(researcher)
            
            logger.info(f"ğŸ“Š Investigadores extraÃ­dos de datos existentes: {len(unique_researchers)}")
            return unique_researchers
            
        except Exception as e:
            logger.error(f"Error extrayendo investigadores: {e}")
            return []

    def extract_researcher_patterns(self, content: str, section_name: str) -> List[Dict[str, Any]]:
        """Extraer patrones de investigadores del contenido"""
        researchers = []
        
        try:
            import re
            
            # Patrones para encontrar investigadores
            patterns = [
                r'Dr\.?\s+([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+)+)',
                r'Dra\.?\s+([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+)+)',
                r'Profesor(?:a)?\s+([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+)+)',
                r'Investigador(?:a)?\s+([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+)+)',
                r'([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+)+),?\s+PhD',
                r'([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+)+),?\s+Mg\.',
                r'([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ¼]+)+),?\s+M\.Sc\.',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    name = match.strip()
                    if len(name.split()) >= 2:  # Al menos nombre y apellido
                        researcher = {
                            'name': name,
                            'source_section': section_name,
                            'department': self.infer_department(section_name),
                            'extraction_method': 'pattern_matching',
                            'found_in': 'existing_data'
                        }
                        researchers.append(researcher)
            
            return researchers
            
        except Exception as e:
            logger.debug(f"Error en extracciÃ³n de patrones: {e}")
            return []

    def infer_department(self, section_name: str) -> str:
        """Inferir departamento basado en el nombre de la secciÃ³n"""
        section_lower = section_name.lower()
        
        dept_mappings = {
            'medicina': 'Facultad de Medicina',
            'enfermeria': 'Facultad de EnfermerÃ­a y RehabilitaciÃ³n',
            'ingenieria': 'Facultad de IngenierÃ­a',
            'comunicacion': 'Facultad de ComunicaciÃ³n',
            'economia': 'Escuela Internacional de Ciencias EconÃ³micas y Administrativas',
            'administracion': 'Escuela Internacional de Ciencias EconÃ³micas y Administrativas',
            'derecho': 'Facultad de Derecho y Ciencias PolÃ­ticas',
            'psicologia': 'Facultad de PsicologÃ­a',
            'educacion': 'Facultad de EducaciÃ³n',
            'filosofia': 'Facultad de FilosofÃ­a y Ciencias Humanas'
        }
        
        for keyword, department in dept_mappings.items():
            if keyword in section_lower:
                return department
        
        return 'Universidad de la Sabana'

    def extract_publications_from_existing_data(self) -> List[Dict[str, Any]]:
        """Extraer informaciÃ³n de publicaciones de datos existentes"""
        publications = []
        
        try:
            sections_data = self.existing_data.get('sections_data', {})
            
            for section_name, section_data in sections_data.items():
                section_content = section_data.get('content', '')
                
                # Buscar patrones de publicaciones
                publications_found = self.extract_publication_patterns(section_content, section_name)
                publications.extend(publications_found)
            
            logger.info(f"ğŸ“š Publicaciones extraÃ­das de datos existentes: {len(publications)}")
            return publications
            
        except Exception as e:
            logger.error(f"Error extrayendo publicaciones: {e}")
            return []

    def extract_publication_patterns(self, content: str, section_name: str) -> List[Dict[str, Any]]:
        """Extraer patrones de publicaciones del contenido"""
        publications = []
        
        try:
            import re
            
            # Patrones para encontrar publicaciones
            patterns = [
                r'(?:doi:|DOI:)\s*(10\.\d+/[^\s]+)',
                r'(?:Journal|Revista|Conference|Conferencia):\s*([^.\n]+)',
                r'(?:Published|Publicado|Appeared)(?:\s+in)?\s*([^.\n]+)',
                r'"([^"]+)"(?:\s*\(\d{4}\))',  # TÃ­tulos entre comillas con aÃ±o
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    title = match.strip()
                    if len(title) > 10:  # Filtrar tÃ­tulos muy cortos
                        publication = {
                            'title': title,
                            'source_section': section_name,
                            'extraction_method': 'pattern_matching',
                            'found_in': 'existing_data',
                            'year': self.extract_year_from_context(content, title)
                        }
                        publications.append(publication)
            
            return publications
            
        except Exception as e:
            logger.debug(f"Error en extracciÃ³n de publicaciones: {e}")
            return []

    def extract_year_from_context(self, content: str, title: str) -> str:
        """Extraer aÃ±o del contexto alrededor del tÃ­tulo"""
        try:
            import re
            
            # Buscar aÃ±os cerca del tÃ­tulo
            title_pos = content.find(title)
            if title_pos != -1:
                context = content[max(0, title_pos-100):title_pos+len(title)+100]
                year_pattern = r'\b(20\d{2})\b'
                years = re.findall(year_pattern, context)
                if years:
                    return years[0]
            
            return 'N/A'
            
        except Exception as e:
            return 'N/A'

    def clean_research_units(self) -> List[Dict[str, Any]]:
        """Limpiar y estructurar informaciÃ³n de unidades de investigaciÃ³n"""
        clean_units = []
        
        try:
            raw_units = self.new_units_data.get('research_units', [])
            
            for unit in raw_units:
                # Filtrar unidades con nombres vÃ¡lidos
                name = unit.get('name', '').strip()
                if not name or len(name) < 5 or 'Universidad' in name and '(1)' in name:
                    continue
                
                clean_unit = {
                    'name': name,
                    'unit_id': unit.get('unit_id', ''),
                    'type': unit.get('type', '').replace('Unidad organizativa:', '').strip(),
                    'profile_url': unit.get('profile_url', ''),
                    'research_areas': self.extract_clean_research_areas(unit),
                    'category': self.extract_category(unit),
                    'status': 'active'
                }
                
                clean_units.append(clean_unit)
            
            logger.info(f"ğŸ›ï¸ Unidades limpias procesadas: {len(clean_units)}")
            return clean_units
            
        except Exception as e:
            logger.error(f"Error limpiando unidades: {e}")
            return []

    def extract_clean_research_areas(self, unit: Dict[str, Any]) -> List[str]:
        """Extraer Ã¡reas de investigaciÃ³n limpias"""
        try:
            areas = unit.get('detailed_info', {}).get('research_areas', [])
            clean_areas = []
            
            for area in areas:
                if isinstance(area, str) and len(area) > 10:
                    # Limpiar texto de categorÃ­as
                    if 'CategorÃ­a MinCiencias' in area:
                        # Extraer solo las categorÃ­as relevantes
                        import re
                        categories = re.findall(r'CategorÃ­a ([AB])', area)
                        if categories:
                            clean_areas.append(f"CategorÃ­a MinCiencias: {categories[0]}")
                    else:
                        clean_areas.append(area[:100])  # Limitar longitud
            
            return clean_areas
            
        except Exception as e:
            return []

    def extract_category(self, unit: Dict[str, Any]) -> str:
        """Extraer categorÃ­a de la unidad"""
        try:
            areas = unit.get('detailed_info', {}).get('research_areas', [])
            for area in areas:
                if 'CategorÃ­a MinCiencias2022' in str(area):
                    import re
                    match = re.search(r'2022:\s*CategorÃ­a\s*([AB])', str(area))
                    if match:
                        return f"MinCiencias CategorÃ­a {match.group(1)}"
            return 'Sin categorÃ­a'
            
        except Exception as e:
            return 'Sin categorÃ­a'

    def build_hybrid_context(self) -> Dict[str, Any]:
        """Construir contexto hÃ­brido completo"""
        logger.info("ğŸ”§ CONSTRUYENDO CONTEXTO HÃBRIDO")
        
        # Extraer informaciÃ³n de diferentes fuentes
        researchers = self.extract_researchers_from_existing_data()
        publications = self.extract_publications_from_existing_data()
        clean_units = self.clean_research_units()
        
        # Crear contexto estructurado
        context = {
            "metadata": {
                "created_date": datetime.now().isoformat(),
                "source_files": [
                    self.config.existing_data_path,
                    self.config.new_units_data_path
                ],
                "extraction_method": "hybrid_combination",
                "total_cost": self.existing_data.get('metadata', {}).get('total_cost', 0) + 
                             self.new_units_data.get('metadata', {}).get('total_cost', 0),
                "summary": {
                    "research_units": len(clean_units),
                    "researchers": len(researchers),
                    "publications": len(publications),
                    "data_quality": "high" if len(researchers) > 10 else "medium"
                }
            },
            "research_units": clean_units,
            "researchers": researchers,
            "publications": publications,
            "knowledge_categories": {
                "biomedical_research": [u for u in clean_units if 'biomÃ©dic' in u['name'].lower() or 'CIBUS' in u['name']],
                "communication": [u for u in clean_units if 'comunicaciÃ³n' in u['name'].lower()],
                "engineering": [u for u in clean_units if 'ingenier' in u['name'].lower()],
                "medicine": [u for u in clean_units if 'medicina' in u['name'].lower() or 'clÃ­nica' in u['name'].lower()],
                "business": [u for u in clean_units if 'econom' in u['name'].lower() or 'admin' in u['name'].lower()],
                "law": [u for u in clean_units if 'derecho' in u['name'].lower()],
                "education": [u for u in clean_units if 'educaciÃ³n' in u['name'].lower()]
            },
            "search_capabilities": {
                "can_search_researchers": True,
                "can_search_units": True,
                "can_search_publications": True,
                "can_provide_details": True,
                "supported_queries": [
                    "investigadores por Ã¡rea",
                    "unidades de investigaciÃ³n",
                    "publicaciones cientÃ­ficas",
                    "grupos de investigaciÃ³n",
                    "categorÃ­as MinCiencias"
                ]
            }
        }
        
        self.hybrid_context = context
        return context

    def save_hybrid_context(self) -> bool:
        """Guardar contexto hÃ­brido"""
        try:
            os.makedirs(os.path.dirname(self.config.output_path), exist_ok=True)
            
            with open(self.config.output_path, 'w', encoding='utf-8') as f:
                json.dump(self.hybrid_context, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ’¾ Contexto hÃ­brido guardado en: {self.config.output_path}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando contexto hÃ­brido: {e}")
            return False

    def create_agent_integration_guide(self) -> str:
        """Crear guÃ­a de integraciÃ³n para el agente"""
        guide = f"""
# ğŸ¤– GUÃA DE INTEGRACIÃ“N - PURE KNOWLEDGE BASE

## ğŸ“Š RESUMEN DE DATOS DISPONIBLES

### ğŸ›ï¸ **Unidades de InvestigaciÃ³n**: {len(self.hybrid_context.get('research_units', []))}
- Centros de investigaciÃ³n biomÃ©dica
- Facultades y escuelas
- Grupos de investigaciÃ³n especializados
- CategorÃ­as MinCiencias (A y B)

### ğŸ‘¥ **Investigadores**: {len(self.hybrid_context.get('researchers', []))}
- Profesores investigadores
- Doctores y especialistas
- Perfiles acadÃ©micos completos

### ğŸ“š **Publicaciones**: {len(self.hybrid_context.get('publications', []))}
- ArtÃ­culos cientÃ­ficos
- Conferencias y ponencias
- ProducciÃ³n acadÃ©mica

## ğŸ”§ FUNCIONES DISPONIBLES PARA EL AGENTE

### 1. `buscar_unidades(query: str)`
Busca unidades de investigaciÃ³n por nombre, Ã¡rea o categorÃ­a.

### 2. `buscar_investigadores(query: str)`
Encuentra investigadores por nombre, departamento o Ã¡rea de especializaciÃ³n.

### 3. `buscar_publicaciones(query: str, year: str = None)`
Localiza publicaciones cientÃ­ficas por tÃ­tulo, autor o aÃ±o.

### 4. `obtener_estadisticas_facultad(facultad: str)`
Proporciona estadÃ­sticas completas de una facultad especÃ­fica.

### 5. `listar_categorias_minciencias()`
Lista todas las unidades organizadas por categorÃ­a MinCiencias.

## ğŸ¯ CASOS DE USO COMUNES

1. **"Â¿QuÃ© investigadores hay en el Ã¡rea de medicina?"**
   â†’ Usar `buscar_investigadores("medicina")`

2. **"Â¿CuÃ¡les son los grupos de investigaciÃ³n en ingenierÃ­a?"**
   â†’ Usar `buscar_unidades("ingenierÃ­a")`

3. **"Â¿QuÃ© publicaciones recientes hay sobre biomedicina?"**
   â†’ Usar `buscar_publicaciones("biomedicina", "2024")`

4. **"Â¿CuÃ¡ntos grupos tiene categorÃ­a A en MinCiencias?"**
   â†’ Usar `listar_categorias_minciencias()`

## ğŸ“ˆ CALIDAD DE DATOS
- **Estado**: âœ… Operacional
- **Cobertura**: {len(self.hybrid_context.get('research_units', []))} unidades mapeadas
- **ActualizaciÃ³n**: {datetime.now().strftime('%Y-%m-%d')}
- **Confiabilidad**: Alta (datos de Pure oficial)

## ğŸš€ PRÃ“XIMOS PASOS
1. Integrar funciones en el agente conversacional
2. Probar consultas comunes
3. Expandir con mÃ¡s datos de investigadores
4. Automatizar actualizaciones periÃ³dicas
"""
        
        guide_path = "scraped_data/PURE_AGENT_INTEGRATION_GUIDE.md"
        try:
            with open(guide_path, 'w', encoding='utf-8') as f:
                f.write(guide)
            logger.info(f"ğŸ“– GuÃ­a de integraciÃ³n creada: {guide_path}")
        except Exception as e:
            logger.error(f"Error creando guÃ­a: {e}")
        
        return guide

def main():
    """FunciÃ³n principal"""
    config = HybridContextConfig()
    builder = HybridContextBuilder(config)
    
    logger.info("ğŸš€ INICIANDO CONSTRUCCIÃ“N DE CONTEXTO HÃBRIDO")
    
    try:
        # Cargar datos
        existing_loaded = builder.load_existing_data()
        units_loaded = builder.load_new_units_data()
        
        if not existing_loaded and not units_loaded:
            logger.error("âŒ No se pudieron cargar datos de ninguna fuente")
            return
        
        # Construir contexto hÃ­brido
        context = builder.build_hybrid_context()
        
        if context:
            # Guardar contexto
            if builder.save_hybrid_context():
                # Crear guÃ­a de integraciÃ³n
                builder.create_agent_integration_guide()
                
                logger.info("\n" + "="*60)
                logger.info("ğŸ‰ CONTEXTO HÃBRIDO CREADO EXITOSAMENTE")
                logger.info(f"ğŸ›ï¸ Unidades: {context['metadata']['summary']['research_units']}")
                logger.info(f"ğŸ‘¥ Investigadores: {context['metadata']['summary']['researchers']}")
                logger.info(f"ğŸ“š Publicaciones: {context['metadata']['summary']['publications']}")
                logger.info(f"ğŸ’° Costo total: {context['metadata']['total_cost']} crÃ©ditos")
                logger.info("âœ… Listo para integraciÃ³n con agente")
                logger.info("="*60)
            else:
                logger.error("âŒ Error guardando contexto hÃ­brido")
        else:
            logger.error("âŒ Error construyendo contexto hÃ­brido")
            
    except Exception as e:
        logger.error(f"Error en construcciÃ³n hÃ­brida: {e}")

if __name__ == "__main__":
    main()
